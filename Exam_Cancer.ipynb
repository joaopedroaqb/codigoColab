{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ4hzQs6buuv"
      },
      "source": [
        "Relatorio:\n",
        "\n",
        "* Serão 30 tipos de atributos.\n",
        "  - Com 3 subdivisão:\n",
        "    - mean / media\n",
        "    - standart error / erro padrão\n",
        "    - worst, largest / pior, maior\n",
        "  \n",
        "* No total temos 569 números de instancia. \n",
        "* tendo no final dois valores existentes\n",
        "  - Benigno ou Maligno."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7crb9Plx7ZWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaO653oQfKjr"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtksPpr5f6QY"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size) #full connected\n",
        "    self.relu = torch.nn.ReLU() #(0, infinito)\n",
        "    self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "    self.sigmoid = torch.nn.Sigmoid() #(0, 1)\n",
        "  def forward(self, x):\n",
        "    hidden = self.fc1(x)\n",
        "    relu = self.relu(hidden)\n",
        "    output = self.fc2(relu)\n",
        "    output = self.sigmoid(output)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEG3VXZtgD1_"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "bc = datasets.load_breast_cancer()\n",
        "dados = bc.data\n",
        "classes = bc.target\n",
        "nomesClasses = bc.target_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZNC7SXIjPpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf088a05-e140-40ff-ddfc-d0a07ae377b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "classes.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32pS018rjULt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d1c4b0-5764-400a-cc9b-ae2f2b434d4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "        1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "        8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "        8.758e-02],\n",
              "       ...,\n",
              "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "        7.820e-02],\n",
              "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "        1.240e-01],\n",
              "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "        7.039e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpzON1BLIWct"
      },
      "outputs": [],
      "source": [
        "for coluna in dados.T:\n",
        "  # print(coluna.max()) # Valores máximos de cada coluna\n",
        "  if coluna.max() < 1:\n",
        "    coluna = coluna / 1\n",
        "  elif coluna.max() < 10:\n",
        "    coluna /= 10\n",
        "  elif coluna.max() < 100:\n",
        "    coluna /= 100\n",
        "  elif coluna.max() < 1000:\n",
        "    coluna /= 1000\n",
        "  elif coluna.max() < 10000:\n",
        "    coluna /= 10000\n",
        "  else:\n",
        "    print('Erro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-Uvv_piqJwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267c8051-3f87-4596-9bdf-38e28a18a042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
            "        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
            "        1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
            "        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
            "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
            "        0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
            "        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
            "        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
            "        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
            "        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
            "        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
            "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
            "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.])\n"
          ]
        }
      ],
      "source": [
        "entrada = torch.FloatTensor(dados)\n",
        "saida = torch.FloatTensor(classes)\n",
        "print(saida)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dkb5xrPQlpCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84144684-bcca-49dd-82e3-d537c796489a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1799, 0.1038, 0.1228,  ..., 0.2654, 0.4601, 0.1189],\n",
            "        [0.2057, 0.1777, 0.1329,  ..., 0.1860, 0.2750, 0.0890],\n",
            "        [0.1969, 0.2125, 0.1300,  ..., 0.2430, 0.3613, 0.0876],\n",
            "        ...,\n",
            "        [0.1660, 0.2808, 0.1083,  ..., 0.1418, 0.2218, 0.0782],\n",
            "        [0.2060, 0.2933, 0.1401,  ..., 0.2650, 0.4087, 0.1240],\n",
            "        [0.0776, 0.2454, 0.0479,  ..., 0.0000, 0.2871, 0.0704]]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
            "        0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
            "        1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
            "        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
            "        0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
            "        0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
            "        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
            "        1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
            "        1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
            "        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
            "        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
            "        0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
            "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
            "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
            "tensor([[0.1095, 0.2135, 0.0719,  ..., 0.1424, 0.2964, 0.0961],\n",
            "        [0.1453, 0.1398, 0.0939,  ..., 0.1069, 0.2606, 0.0781],\n",
            "        [0.1513, 0.2981, 0.0967,  ..., 0.0658, 0.3233, 0.0617],\n",
            "        ...,\n",
            "        [0.1394, 0.1317, 0.0903,  ..., 0.1015, 0.2160, 0.0725],\n",
            "        [0.1775, 0.2803, 0.1173,  ..., 0.1970, 0.2972, 0.0908],\n",
            "        [0.0873, 0.1684, 0.0553,  ..., 0.0000, 0.2445, 0.0887]]) tensor([0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
            "        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
            "        0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
            "        0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
            "        1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
            "        1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
            "        1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
            "        1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
            "        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
            "        1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
            "        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
            "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
            "        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
            "        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
            "        1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
            "        1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
            "        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
            "        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
            "        1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
            "        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
            "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
            "        0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
            "        1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
            "        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "print(entrada, saida)\n",
        "entrada, saida = shuffle(entrada, saida)\n",
        "print(entrada, saida)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBPqiQdpl5ei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc423cd-722a-41f0-d449-44f364d46999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1242, 0.1504, 0.0786,  ..., 0.0405, 0.2901, 0.0678],\n",
            "        [0.1940, 0.2350, 0.1291,  ..., 0.1564, 0.2920, 0.0761],\n",
            "        [0.2722, 0.2187, 0.1821,  ..., 0.2688, 0.2856, 0.0808],\n",
            "        ...,\n",
            "        [0.1394, 0.1317, 0.0903,  ..., 0.1015, 0.2160, 0.0725],\n",
            "        [0.1775, 0.2803, 0.1173,  ..., 0.1970, 0.2972, 0.0908],\n",
            "        [0.0873, 0.1684, 0.0553,  ..., 0.0000, 0.2445, 0.0887]])\n",
            "tensor([1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
            "        1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
            "        0., 0., 1., 1., 0., 1., 0., 1.])\n"
          ]
        }
      ],
      "source": [
        "entrada_treinamento = entrada[0:525, :]\n",
        "saida_treinamento = saida[0:525]\n",
        "entrada_testes = entrada[525:569, :]\n",
        "saida_testes = saida[525:569]\n",
        "print(entrada_testes)\n",
        "print(saida_testes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y14gs1jimk-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef34cabc-8925-47c0-9a57-2929e0bbc783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([525, 30])\n",
            "Net(\n",
            "  (fc1): Linear(in_features=30, out_features=25, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=25, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Montar o modelo para o treinamento\n",
        "print(entrada_treinamento.size())\n",
        "input_size = entrada_treinamento.size()[1]\n",
        "hidden_size = 25\n",
        "modelo = Net(input_size, hidden_size)\n",
        "print(modelo)\n",
        "\n",
        "# Configurações do modelo\n",
        "criterion = torch.nn.BCELoss() # Binary Cross Entropy\n",
        "criterion = torch.nn.MSELoss() # Mean Square Error\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr = 0.8, momentum = 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pJb_Z-Sm6r4",
        "outputId": "e54373d0-037f-4334-ac66-89db262c3f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss: 0.25235652923583984\n",
            "Epoch 10000: train loss: 0.012504125013947487\n",
            "Epoch 20000: train loss: 0.01085455622524023\n",
            "Epoch 30000: train loss: 0.009818676859140396\n",
            "Epoch 40000: train loss: 0.009008088149130344\n",
            "Epoch 50000: train loss: 0.008330550976097584\n",
            "Epoch 60000: train loss: 0.007768820971250534\n",
            "Epoch 70000: train loss: 0.007316704839468002\n",
            "Epoch 80000: train loss: 0.006966878660023212\n",
            "Epoch 90000: train loss: 0.00670286500826478\n",
            "Epoch 100000: train loss: 0.00650563882663846\n",
            "Epoch 110000: train loss: 0.006358070764690638\n",
            "Epoch 120000: train loss: 0.00624697282910347\n",
            "Epoch 130000: train loss: 0.006161903031170368\n",
            "Epoch 140000: train loss: 0.006096027325838804\n",
            "Epoch 150000: train loss: 0.0060442169196903706\n",
            "Epoch 160000: train loss: 0.0060026939027011395\n",
            "Epoch 170000: train loss: 0.005969048477709293\n",
            "Epoch 180000: train loss: 0.005941497161984444\n",
            "Epoch 190000: train loss: 0.00591841759160161\n",
            "Epoch 200000: train loss: 0.005899039562791586\n",
            "Epoch 210000: train loss: 0.005882567726075649\n",
            "Epoch 220000: train loss: 0.00586846936494112\n",
            "Epoch 230000: train loss: 0.005856284871697426\n",
            "Epoch 240000: train loss: 0.005845594219863415\n",
            "Epoch 250000: train loss: 0.005836285185068846\n",
            "Epoch 260000: train loss: 0.005828049965202808\n",
            "Epoch 270000: train loss: 0.005820722319185734\n",
            "Epoch 280000: train loss: 0.005814211908727884\n",
            "Epoch 290000: train loss: 0.005808355752378702\n",
            "Epoch 300000: train loss: 0.005803088657557964\n",
            "Epoch 310000: train loss: 0.005798323545604944\n",
            "Epoch 320000: train loss: 0.005793990101665258\n",
            "Epoch 330000: train loss: 0.005790043622255325\n",
            "Epoch 340000: train loss: 0.005786438938230276\n",
            "Epoch 350000: train loss: 0.005783129949122667\n",
            "Epoch 360000: train loss: 0.005780085455626249\n",
            "Epoch 370000: train loss: 0.005777266807854176\n",
            "Epoch 380000: train loss: 0.00577465770766139\n",
            "Epoch 390000: train loss: 0.005772274453192949\n",
            "Epoch 400000: train loss: 0.005770029500126839\n",
            "Epoch 410000: train loss: 0.005767954979091883\n",
            "Epoch 420000: train loss: 0.005766006652265787\n",
            "Epoch 430000: train loss: 0.005764173809438944\n",
            "Epoch 440000: train loss: 0.005762447603046894\n",
            "Epoch 450000: train loss: 0.005760814528912306\n",
            "Epoch 460000: train loss: 0.005759296473115683\n",
            "Epoch 470000: train loss: 0.005757872946560383\n",
            "Epoch 480000: train loss: 0.005756537429988384\n",
            "Epoch 490000: train loss: 0.005755282007157803\n",
            "Epoch 500000: train loss: 0.005754080135375261\n",
            "Epoch 510000: train loss: 0.005752942059189081\n",
            "Epoch 520000: train loss: 0.005751872900873423\n",
            "Epoch 530000: train loss: 0.00575086148455739\n",
            "Epoch 540000: train loss: 0.005749894306063652\n",
            "Epoch 550000: train loss: 0.005748964846134186\n",
            "Epoch 560000: train loss: 0.0057480731047689915\n",
            "Epoch 570000: train loss: 0.005747219081968069\n",
            "Epoch 580000: train loss: 0.005746401380747557\n",
            "Epoch 590000: train loss: 0.0057456172071397305\n",
            "Epoch 600000: train loss: 0.00574486143887043\n",
            "Epoch 610000: train loss: 0.005744139198213816\n",
            "Epoch 620000: train loss: 0.005743457470089197\n",
            "Epoch 630000: train loss: 0.005742817651480436\n",
            "Epoch 640000: train loss: 0.005742204375565052\n",
            "Epoch 650000: train loss: 0.0057416134513914585\n",
            "Epoch 660000: train loss: 0.0057410430163145065\n",
            "Epoch 670000: train loss: 0.005740493070334196\n",
            "Epoch 680000: train loss: 0.005739962216466665\n",
            "Epoch 690000: train loss: 0.0057394434697926044\n",
            "Epoch 700000: train loss: 0.005738942883908749\n",
            "Epoch 710000: train loss: 0.005738457664847374\n",
            "Epoch 720000: train loss: 0.005737988743931055\n",
            "Epoch 730000: train loss: 0.005737540777772665\n",
            "Epoch 740000: train loss: 0.0057371086440980434\n",
            "Epoch 750000: train loss: 0.00573669234290719\n",
            "Epoch 760000: train loss: 0.005736286751925945\n",
            "Epoch 770000: train loss: 0.005735894665122032\n",
            "Epoch 780000: train loss: 0.005735518876463175\n",
            "Epoch 790000: train loss: 0.005735164042562246\n",
            "Epoch 800000: train loss: 0.005734823178499937\n",
            "Epoch 810000: train loss: 0.0057344939559698105\n",
            "Epoch 820000: train loss: 0.005734172184020281\n",
            "Epoch 830000: train loss: 0.0057338569313287735\n",
            "Epoch 840000: train loss: 0.00573354959487915\n",
            "Epoch 850000: train loss: 0.005733249709010124\n",
            "Epoch 860000: train loss: 0.005732961464673281\n",
            "Epoch 870000: train loss: 0.005732679273933172\n",
            "Epoch 880000: train loss: 0.0057324073277413845\n",
            "Epoch 890000: train loss: 0.005732144694775343\n",
            "Epoch 900000: train loss: 0.0057318857870996\n",
            "Epoch 910000: train loss: 0.005731632467359304\n",
            "Epoch 920000: train loss: 0.005731383804231882\n",
            "Epoch 930000: train loss: 0.005731142126023769\n",
            "Epoch 940000: train loss: 0.005730909761041403\n",
            "Epoch 950000: train loss: 0.005730684846639633\n",
            "Epoch 960000: train loss: 0.005730469711124897\n",
            "Epoch 970000: train loss: 0.005730259232223034\n",
            "Epoch 980000: train loss: 0.005730052012950182\n",
            "Epoch 990000: train loss: 0.005729848984628916\n",
            "Epoch 1000000: train loss: 0.005729637574404478\n",
            "Epoch 1010000: train loss: 0.005729429889470339\n",
            "Epoch 1020000: train loss: 0.005729224998503923\n",
            "Epoch 1030000: train loss: 0.005729024764150381\n",
            "Epoch 1040000: train loss: 0.005728826858103275\n",
            "Epoch 1050000: train loss: 0.005728632677346468\n",
            "Epoch 1060000: train loss: 0.0057284412905573845\n",
            "Epoch 1070000: train loss: 0.0057282522320747375\n",
            "Epoch 1080000: train loss: 0.005728066898882389\n",
            "Epoch 1090000: train loss: 0.00572788342833519\n",
            "Epoch 1100000: train loss: 0.005727703683078289\n",
            "Epoch 1110000: train loss: 0.00572752533480525\n",
            "Epoch 1120000: train loss: 0.005727351177483797\n",
            "Epoch 1130000: train loss: 0.005727178417146206\n",
            "Epoch 1140000: train loss: 0.005727009382098913\n",
            "Epoch 1150000: train loss: 0.005726843141019344\n",
            "Epoch 1160000: train loss: 0.005726679693907499\n",
            "Epoch 1170000: train loss: 0.0057265181094408035\n",
            "Epoch 1180000: train loss: 0.005726360250264406\n",
            "Epoch 1190000: train loss: 0.005726205185055733\n",
            "Epoch 1200000: train loss: 0.005726051516830921\n",
            "Epoch 1210000: train loss: 0.005725899711251259\n",
            "Epoch 1220000: train loss: 0.005725750233978033\n",
            "Epoch 1230000: train loss: 0.0057256026193499565\n",
            "Epoch 1240000: train loss: 0.005725459661334753\n",
            "Epoch 1250000: train loss: 0.005725315771996975\n",
            "Epoch 1260000: train loss: 0.00572517653927207\n",
            "Epoch 1270000: train loss: 0.005725042428821325\n",
            "Epoch 1280000: train loss: 0.00572491530328989\n",
            "Epoch 1290000: train loss: 0.005724797956645489\n",
            "Epoch 1300000: train loss: 0.005724689457565546\n",
            "Epoch 1310000: train loss: 0.00572458328679204\n",
            "Epoch 1320000: train loss: 0.005724478047341108\n",
            "Epoch 1330000: train loss: 0.005724376067519188\n",
            "Epoch 1340000: train loss: 0.005724275019019842\n",
            "Epoch 1350000: train loss: 0.005724175833165646\n",
            "Epoch 1360000: train loss: 0.005724078509956598\n",
            "Epoch 1370000: train loss: 0.005723981186747551\n",
            "Epoch 1380000: train loss: 0.005723888054490089\n",
            "Epoch 1390000: train loss: 0.005723795387893915\n",
            "Epoch 1400000: train loss: 0.0057237036526203156\n",
            "Epoch 1410000: train loss: 0.005723613779991865\n",
            "Epoch 1420000: train loss: 0.005723525304347277\n",
            "Epoch 1430000: train loss: 0.005723439157009125\n",
            "Epoch 1440000: train loss: 0.005723353009670973\n",
            "Epoch 1450000: train loss: 0.005723268259316683\n",
            "Epoch 1460000: train loss: 0.005723185371607542\n",
            "Epoch 1470000: train loss: 0.005723102949559689\n",
            "Epoch 1480000: train loss: 0.005723023787140846\n",
            "Epoch 1490000: train loss: 0.005722947884351015\n"
          ]
        }
      ],
      "source": [
        "epochs = 1500000 # Quantidade de épocas de treinamento\n",
        "\n",
        "errors = [] # Criando um array vazio para guardar os erros de cada epoca\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  # Forward pass\n",
        "  y_pred = modelo(entrada_treinamento)\n",
        "  #Compute Loss\n",
        "  loss = criterion(y_pred.squeeze(), saida_treinamento)\n",
        "  errors.append(loss.item())\n",
        "  if epoch % 10000 == 0:\n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "  #Backward pass\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDaQ7p7wnXTk"
      },
      "outputs": [],
      "source": [
        "y_pred = modelo(entrada_testes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y777BTvvngmU",
        "outputId": "98a92956-90c1-488e-cb20-61fd12585806"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plotcharts(errors):\n",
        "    errors = np.array(errors)\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    graf02 = plt.subplot(1, 2, 1) # nrows, ncols, index\n",
        "    graf02.set_title('Errors')\n",
        "    plt.plot(errors, '-')\n",
        "    plt.xlabel('Epochs')\n",
        "    graf03 = plt.subplot(1, 2, 2)\n",
        "    graf03.set_title('Tests')\n",
        "    a = plt.plot(saida_testes.numpy(), 'yo', label='Real')\n",
        "    plt.setp(a, markersize=10)\n",
        "    a = plt.plot(y_pred.detach().numpy(), 'b+', label='Predicted')\n",
        "    plt.setp(a, markersize=10)\n",
        "    plt.legend(loc=7)\n",
        "    plt.show()\n",
        "plotcharts(errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjunMpdjoRRl",
        "outputId": "d1540a70-1572-471f-8d4e-2cb061537d00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "classes.size"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}